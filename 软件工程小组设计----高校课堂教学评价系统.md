#                                                                                 <img src="https://th.bing.com/th?id=OIP._4WMsvGHwK94HvcUDiOorwHaHI&w=200&h=200&c=9&rs=1&qlt=99&o=6&dpr=1.3&pid=13.1" alt="img" style="float: left; margin-right: 10px;" />

#                                                                                                                                                                                                                                               								           软件工程小组设计---高校课堂教学评价系统

​      **School of Artificial Intelligence,Beijing Normal University**

​                     202211998132 刘畅 产品经理与调研测试

​                      202211081082 练正轩 市场调研与测试人员

​                      202311081058 刘尚 开发人员与前端部署

​                      202211081070 邓力滔 开发人员与后端算法

​                      202211081020 张彤阳 开发人员与后端算法



[toc]

### 一、项目总览

##### 1 项目背景

教育数字化是主动适应新一轮科技革命和产业变革的必然选择，是促进更高质量教育公平的必然要求，是教育普及化阶段的必然趋势，是推动教育创新发展的必由之路。党的二十大报告首次提出“推进教育数字化，建设全民终身学习的学习型社会、学习型大国”。习近平总书记在中共中央政治局第五次集体学习时强调 “教育数字化是我国开辟教育发展新赛道和塑造教育发展新优势的重要突破口”。教育部部长指出“实施人工智能赋能行动，促进智能技术与教育教学、科学研究深度融合”。因此，教育数字化建设已受到高度重视。

高校课堂教学评价作为提高教学质量、促进教育改革和创新的重要手段之一，具有重要的理论与实践意义。教学评价不仅是对教师教学工作的客观评价，更是对教学内容、方法以及学生学习情况的全面检视。通过评价和反馈，教师能够了解自己教学中的优势和不足，从而有针对性地改进教学内容和方法，推动教学质量的持续提升。高校课堂教学评价也为建立良好的教学管理体系提供了重要支持，为教学管理部门提供了全面了解教学工作情况的途径，有助于及时发现和解决教学中存在的问题，提升整体教学水平。

然而，传统的教学评价方法存在诸多局限性，如人工评价模式耗费时间精力、评价过程主观性强等。随着人工智能和大数据等前沿技术的快速发展，数字化的教学评价模式逐渐受到重视。数字化评价通过计算机技术支持和评价功能融合匹配的方式，具有动态监测、实时反馈等特点，能够消除传统评价模式的片面性和低效率问题，实现教学增值性评价。同时，可视化的系统可以更好的掌控教师的课堂表现与更客观的教学评价，不仅节约人力，还可以贴近校园生活与广大学生群体的直接利益，在这一背景下，借助人工智能和数据处理技术，改进课堂教学评价方法，强化教学过程评价、探索增值评价，借助计算机开发经验，提供更为快捷更为高效的反馈机制、构建技术支撑下的教育评价新模式成为新一轮教学改革的关键。

因此，为了解决传统评价方法存在的问题，本项目旨在利用计算机视觉与自然语言处理技术，如人脸检测、视线检测、行为识别、表情识别、语音识别、文本匹配等人工智能技术方法，并开发一个完整的可视化系统完整的对教师教学过程中的教学行为和教学内容等进行实时感知和统计评估，对教师教学特点进行深入掌握和分析，为教学质量的改善和提升提供科学依据和支持。

同时，该项目配置了线上意见反馈、评分质疑等机制，帮助评价体系及时调整，更好的重建数字化教学方式。

##### 2 项目目标

本项目的研究目标是深入探索和构建一个适应教育数字化时代的、基于数据驱动的高校课堂教学评价系统。打破传统单一维度、以分数为主的评价机制，强化对课堂图像、音视频、文本等多模态、全方位、长时段数据的感知、采集、分析和监测，基于以人为中心的多模态感知与分析技术，使得课堂中的过程性数据转换为课堂行为等可解读性评价依据。同时，以教学目标达成为导向，实现教师个体行为、认知与情感等多维度测评，并结合合理搞高效的可视化系统及时发现课堂教学中可能出现的问题，帮助教师改进授课质量。

##### 3 项目受众

本项目适用于高校评价单位，高校教学质量分析单位、机关，广大教师群体与学生群体，及时反馈、教学分析标准全公开透明，可以帮助教师群体及时发现教学问题改正，同时可以对高校教师的教学质量加以监督，以更客观的指标和系统反馈帮助教学向好向善。同时设置的系统反馈功能，可以帮助学生、教师对系统提供意见出口，及时调整系统评价和重建评价体系，对教学过程中的参与对象老师与学生都大有裨益。

##### 4项目调研（已有项目及方法分析）













##### 5系统框架

本项目主要包括评价指标体系调研与构建（代码化）、多模态课堂教学智能分析和高校课堂教学评价与前端反馈三个部分。

主要系统框架如下：

**评价指标体系构建（代码化）。**制定代码层适用于AI教学评测的课堂多维度评价体系指标，例如教学风格、知识点偏移度、课件依赖性等，智能化生成课堂教学过程评测报告，包括视线分布图、行为分布图、表情分布图、位移热力图和知识点分布图等多种评测结果展示，实现课堂教学测评量化指标的可视化呈现。

**多模态课堂教学智能分析。**旨在利用人工智能技术，如人脸检测、动作识别、表情识别、自然语言处理等，对收集到的视频、音频、文本等多模态数据进行深度分析。在单模态数据分析中，对教学视频数据进行处理，主要包括利用人脸检测与关键点检测技术实现对教师位置的实时感知；利用视线检测技术对教师的视线关注区域进行识别；利用表情识别和动作识别对教师的情绪和动作进行检测。在跨模态数据分析中，对课堂语音、课件、教学大纲等语音和文本多模态数据进行处理，主要包括利用语音识别和文本匹配技术，检测教师的课堂教学内容是否存在敏感词汇与危险言论，实现课堂教学意识形态分析；利用语音识别和光学字符识别（Optical Character Recognition, OCR）检测教师是否存在照着课件读的现象，评估课件依赖程度；利用语音识别和语义理解等技术，实时分析教师的教学内容，并与教学大纲进行匹配，检测知识点偏移程度。

**高校课堂教学评价与前端反馈。**本项目计划构建Web端展示平台，对多模态课堂教学分析结果进行可视化展示，实现教学过程智能感知与画像。同时，对比分析智能评价机制反馈前后的教学质量，进而对该智能评价机制持续改进和优化。同时，可以同时处理多地实时视频数据，用最快实时反馈到用户端。

#### 二、按照⾯向对象设计原则和⽅法全⾯考虑软件设计⽅案  

##### （1）评价体系代码化架构





##### （2）多模态课堂分析

##### 主要模块介绍

###### 1 数据采集模块

- **职责**：负责从视频、音频等多模态数据源中采集数据。
- **类设计**：
  - `DataCollector`：抽象基类，定义采集数据的接口。
  - `VideoDataCollector`：继承自`DataCollector`，实现视频数据采集。
  - `AudioDataCollector`：继承自`DataCollector`，实现音频数据采集。


###### 2 数据处理模块

- **职责**：对采集的数据进行预处理和特征提取，为后续模块的推理分析打下基础。
- **类设计**：
  - `DataProcessor`：抽象基类，定义数据处理接口。
  - `VideoDataProcessor`：继承自`DataProcessor`，实现视频数据的处理。
  - `AudioDataProcessor`：继承自`DataProcessor`，实现音频数据的处理。


###### 3 单模态分析模块

- **职责**：对单模态数据进行分析，包括位移、视线、行为、表情分析。
- **类设计**：
  - `ModalityAnalyzer`：抽象基类，定义单模态分析接口，定义各个单模态分析模块的公用基础属性和功能。
  - `DisplacementAnalyzer`：继承自`ModalityAnalyzer`，实现位移分析，利用人脸检测与关键点检测技术实现对教师位置的实时感知。
  - `VisionAnalyzer`：继承自`ModalityAnalyzer`，实现视线分析，利用视线检测技术对教师的视线关注区域进行识别。
  - `BehaviorAnalyzer`：继承自`ModalityAnalyzer`，实现行为分析。
  - `ExpressionAnalyzer`：继承自`ModalityAnalyzer`，实现表情分析。


###### 4 跨模态分析模块

- **职责**：对多模态数据进行综合分析，包括意识形态、知识点偏移、课件依赖性分析。
- **类设计**：
  - `CrossModalityAnalyzer`：抽象基类，定义跨模态分析接口。
  - `IdeologyAnalyzer`：继承自`CrossModalityAnalyzer`，实现意识形态分析。
  - `KnowledgeDeviationAnalyzer`：继承自`CrossModalityAnalyzer`，实现知识点偏移分析。
  - `CoursewareDependenceAnalyzer`：继承自`CrossModalityAnalyzer`，实现课件依赖性分析。


###### 5 可视化与报告模块

- **职责**：将分析结果进行可视化展示，并生成教学质量评估报告。
- **类设计**：
  - `Visualization`：负责将分析结果转化为图表。
  - `ReportGenerator`：负责生成教学质量评估报告。

###### 关键算法原理介绍：

###### (a)位移分析

在教学评价中，位置移动（位移）指教师在课堂上站立位置的变化。已有文献中提出，教师授课过程中应适当走到学生当中，在心理上接近学生；学生在考试或专心做练习时不希望有教师在他们身边走动或停留，如果这样可能会分散他们的注意力，甚至造成情绪紧张；教师不应走到教室偏后侧进行讲解和演示，否则会使前面的学生看不到教师的演示。因此，教师的位移对于课堂授课质量有一定的影响。本项目通过人脸检测技术对教师的位置进行实时定位，并利用热力图绘制教师在教室中的位移范围，从而便于对教师的位移进行挖掘与分析。

（1）技术路线

![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image002.gif)

图 1教室鸟瞰图 2人脸检测框和关键点

**![descript](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image004.jpg)**

图 3 RetinaFace模型架构

为了更好地记录教师的教学过程，通常在面向讲台，教室的中后方或者后方部署摄像头，对教师数据进行实时采集，如图1所示。而教师的位移主要包含左、右、前、后四个方向。前后表示教师走进或远离摄像头，左右则表示教师相对于摄像头左右移动。为感知教师的实时位置，本项目首先通过RetinaFace进行人脸检测与关键点检测。RetinaFace以ResNet为主干网络，并采用特征金字塔结构，将人脸框预测、二维人脸关键点定位、三维顶点回归作为多任务损失对网络进行训练。将课堂教学的图像帧输入RetinaFace模型，即可得到教师的人脸框和五个人脸关键点（眼睛、鼻尖和嘴角），如图2所示。

通过人脸框可以定位到教师的实时位置，本项目利用鼻尖点的左右移动来粗略估计教师的左右位移，从而得到教师在图像中的移动距离（以像素为单位）。然而，在现实应用中，还需要将该值映射为真实世界的移动距离（以米为单位）。同时，相比于真实世界，图像是二维的，缺少深度信息，因此，无法直接从图像中获得教师的前后移动距离。针对以上问题，需要将像素坐标系转换为世界坐标系从而获得深度信息，并实现映射。这个过程需要相机内外参数（通过相机标定获得）参与计算。然而，考虑到教室的布局和摄像头摆放位置有可能存在差异，需要针对每间教室的具体情况分别进行标定。这种做法费时费力且不存在普适性。因此，本项目对其进行简化和优化，利用“近大远小”的成像特点，采用更为简洁的计算方法。

前后距离的计算公式如下：

![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image006.gif)

其中，![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image008.gif)代表深度值，即教师与相机之间的真实世界距离（以米为单位）。![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image010.gif)为常量，表示人脸的真实世界高度（在最终结果以米为单位的计算中个体差异可以忽略）。![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image012.gif)是人脸在图像中的高度，该值可直接通过人脸检测框的高度计算得到。![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image014.gif)是一个固定常数，用于调整模型以匹配真实情况。该公式基于“近大远小”的原则，将深度值与人脸在图像中的高度建模成反比关系，即离相机越近，人脸检测框越大，反之亦然。

左右距离的计算公式如下：

![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image016.gif)

其中，![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image018.gif)代表教师在真实世界的左右位移（以米为单位）。![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image020.gif)表示在图像中以左上角为坐标原点时，教师鼻尖的横坐标。![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image022.gif)为图像的宽度（以像素为单位）。![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image024.gif)则将坐标原点平移至图像中心，即得到教师在图像中相对于画面中心的距离。该公式直接简化地将真实世界左右距离与图像中的左右距离建模成正比关系，通过计算教师鼻尖的横坐标与图像中心横坐标的差值，并乘以每像素实际距离![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image026.gif)，得到教师在真实世界中的水平距离![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image018.gif)。

通过结合深度计算和水平距离计算，本项目能够实现对目标物体在三维空间中的精确定位，为后续的分析和处理提供了有力的支持。

（2）模块流程

如图4所示，此模块的实现过程为首先调用RetinaFace模型获取当前图像帧中教师的人脸框和5个关键点。然后，根据鼻尖点的左右移动获取教师的左右位置，并根据“近大远小”的原则获取教师的前后位置，并对结果进行输出。当教学视频的所有图像帧处理完毕之后，调用核密度估计算法计算位移热力图并输出。

![descript](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image028.gif)

图 4位移估计流程图

###### (b)视线分析

在教学过程中，教师与学生之间的交流通常通过眼神实现。在课堂中，教师一味低头看课本或者课件，缺乏与学生的眼神交流会导致课程体验不佳。因此，合适的眼神运用方法是教师智慧的体现，对于提高教学效率和管理水平至关重要。本项目通过视线检测算法对教师的视线进行实时估计，并对视线分布进行可视化，以深入挖掘和分析教师的视线规律和特点。

（1）技术路线

![descript](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image076.gif)

图 5 3DGazeNet模型架构

![descript](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image078.gif)

图 6 视线的偏航角和俯仰角

采用3DGazeNet进行视线检测。3DGazeNet提出利用三维眼球网格估计来辅助视线检测，以ResNet18为主干网络，并紧接两层全连接层以同时输出三维人眼网格和三维视线向量，如图5所示。将课堂教学的图像帧输入3DGazeNet模型，即可得到教师的三维视线向量![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image080.gif)，其中![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image082.gif)分别表示三维空间中![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image084.gif)轴的分量。基于三维视线向量，由以下公式可以计算出视线的偏航角和俯仰角（如图6所示)：

![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image086.gif)

其中，![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image088.gif)为偏航角，记录视线的左右偏移；![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image090.gif)为俯仰角，记录视线的上下偏移。本项目通过视线的偏航角和俯仰角将视线的关注区域分为四类：左偏上、左偏下、右偏上、右偏下（如下表所示），以更好地统计和挖掘教师课堂的视线分布规律和特点。

表  视线角度与关注区域的关系

| 序号 | 视线关注区 | 角度值                                                       |
| ---- | ---------- | ------------------------------------------------------------ |
| 1    | 左偏上     | ![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image092.gif) |
| 2    | 左偏下     | ![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image094.gif) |
| 3    | 右偏上     | ![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image096.gif) |
| 4    | 右偏下     | ![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image098.gif) |

（2）模块流程

  此模块执行过程如图7所示，首先调用3DGazeNet模型对当前图像帧中的教师视线进行检测，获取三维视线向量，并计算视线的偏航角和俯仰角。其中，偏航角为正表示视线关注右方区域，为负表示视线关注左方区域；俯仰角为正则表示视线关注偏下方区域，反之表示视线关注偏上方区域。当教学视频的所有图像帧处理完毕之后，输出视线关注分布图。

![descript](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image100.gif)

图 7视线估计流程图

###### (c)行为分析

教师的动作行为对课堂有着深远的影响，它可以直接影响学生的学习效果、课堂氛围和教学质量。例如，教师的引导指示类动作可以帮助学生集中注意力，促进课堂互动，提高学习效率；教师若一直低头看课本，则会减少课堂互动程度，降低学生学习兴趣。此外，动作在一定程度上也能反映出教师的教学类型和教态风格。例如，喜欢面向学生挥舞手臂的教师较大概率属于互动型教学方式。

因此，为了研究教师在教学过程中的行为分布和行为变化，本项目选取了五种常见的课堂行为，并对这些行为进行实时识别，从而评估教师的风格和特点。这五种课堂行为分别是：面向学生挥舞手臂、手指指向某处、使用课本、书写板书和在教室走动。其中，面向学生挥舞手臂和在教室走动可以看作是教师与学生的一种互动方式；手指指向某处表示教师在引导学生的注意力，提高和管理课堂效率；书写板书表示教师利用合理的教学工具进行知识传授；使用课本则反映教师在一定程度上对于课程内容不太熟悉。因此，这五种行为均对教师的评估具有一定价值和意义。

（1）算法原理介绍

![descript](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image115.gif)

图 8教师行为识别模型框架

本项目采用基于骨架点的动作识别对教师的五类动作进行识别。首先使用YOLOv5和StrongSort算法对教学视频中的教师进行目标检测和跟踪，从而定位教师的实时位置。然后，使用HRNet对教师进行骨架点检测。HRNet采用并行多分支网络结构，通过在不同阶段内部实现多尺度特征的反复交融，保持高分辨率表征使最后输出特征更丰富。它包含四个阶段，每个阶段有四个并行的子网络，其分辨率逐渐降低到一半，同时宽度（通道数）增加到两倍。第一个阶段包含4个残差单元并紧随一个![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image117.gif)卷积。第二、三、四阶段分别包含1、4、3个交换块（exchange unit）。每个交换块包含4个残差单元，每个单元包含两个![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image117.gif)卷积以及一个跨分辨率的交换单元。将由YOLOv5和StrongSort检测跟踪到的教师图像输入HRNet模型，即可得到教师的![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image120.gif)个骨骼关键点。

得到骨架点后，采用ST-GCN结合时间和空间信息实现基于骨架点的动作识别。ST-GCN利用时空图对骨架点序列进行分层表示。具体而言，在具有每帧![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image122.gif)个骨架点的![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image124.gif)个图像帧上构造无向时空图![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image126.gif)。其中，节点![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image128.gif)是骨架序列中所有的骨架点。边包含骨骼间连接和帧间连接两个子集。骨骼间连接![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image130.gif)表示每帧图像中不同骨架点构成的边，![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image132.gif)为自然连接的人体关节集合。帧间连接![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image134.gif)表示连续帧中的相同骨架点构成的边。将构造的时空图输入由9层时空图卷积算子构成的ST-GCN，对时间维度和空间维度的数据分别进行卷积操作，最终得到所属的动作类别。

![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image136.gif)

图 9 YOLOv5和StrongSort模型结构示意图

![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image138.gif)

图 10 HRNet模型结构示意图

（2）模块工作流程

如图11所示，此模块首先调用YOLOv5和StrongSort模型对当前图像帧中的教师进行检测和跟踪。然后，利用HRNet模型提取教师的17个骨架点，最后，基于骨架点构造时空图，以时空图为输入，利用ST-GCN模型对教师动作进行识别。当教学视频的所有图像帧处理完毕之后，输出动作分布图。

![descript](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image140.gif)

图 11动作识别流程图

###### (d)表情分析

教师的表情往往伴随着教学的进行而发生变化。当教师专注于教学时，可能会面带微笑，眉毛微微皱起，注视着学生或教材。相反，当教师不够专注时，可能会表现出漫不经心的表情，眼神游离或神情呆滞。此外，教师的表情也可以影响课程效果。友好和温暖的表情可能会增进师生之间的信任和亲近感，促进积极的学习氛围；相反，严肃或冷漠的表情可能会导致师生之间的疏离和隔阂，影响学生的学习体验和情绪状态。因此，教师的表情对授课质量也有一定影响，对教师表情的实时感知与分析也至关重要。

（1）算法原理介绍

  将教师的表情分为中性、开心、惊讶、愤怒、厌恶、悲伤、恐惧七种，并采用ResMaskingNet对其进行实时感知与识别。该网络包含四个主要的残差掩码块(Residual Masking Blocks)。每个残差掩码块包含一个残差层![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image192.gif)和一个掩码块![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image194.gif)。残差层对输入特征图进行非线性转换输出特征图![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image196.gif)，而掩码块则为特征图中的每个元素学习合适的权重以使得网络更加关注相关信息进行决策和分类：

![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image198.gif)

其中，![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image200.gif)为残差掩码块的输入特征图，![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image202.gif)为残差掩码块的输出特征图，![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image204.gif)表示逐元素相乘。将教师课堂的图像帧调整大小为224×224，并将其通过一个步幅为2的3×3卷积层和一个2×2的最大池化层，使其空间大小减小到56×56。接下来，利用四个残差掩码块对池化后的特征图进行非线性变换，分别生成56×56、28×28、14×14、7×7四种空间大小的特征图。最后，输出的特征图通过一个平均池化层和一个全连接层，输出最终的表情类别。

![descript](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image206.gif)

图 12表情分析模型架构

（2）模块工作流程

如图13所示，此模块调用ResMaskingNet模型对当前图像帧中教师的表情进行识别。当教学视频的所有图像帧处理完毕之后，输出表情识别统计结果用以后续分析。

 

![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image208.gif)

图 13表情识别流程图

###### (e)教学类型分析

本项目设计了教学类型评估模块，用于整合多种特征，并输出教师教学风格类型的概括性评价，以便教师在课后迅速了解教学的总体综合评估结果。该模块通过对五类行为的识别结果进行建模评估，利用教师不同课堂行为的分布情况来判断教师的教学风格。举手示意和指示引导通常用于互动型教学，强调师生间的交流与反馈。走动行为表明教师在课堂中较为活跃，可能倾向于激昂型教学，通过动态的授课方式激发学生兴趣。使用课本和书写板书则更多出现在灌输型和庄严型教学中，注重系统性知识的传递和严谨的授课方式。

算法原理介绍

该模块的核心是使用熵权法对各项特征进行权重分配。熵权法通过计算各个特征在数据集中的信息熵，衡量其信息含量和重要性，并据此为每个特征分配适当的权重。这种方法能够更好地平衡不同特征的重要性，使得较为关键的特征在评估过程中得到更高的权重，确保评估结果的准确性和公平性。

熵（Entropy）最初是统计热力学领域的概念，通常与无序、随机或不确定状态相关联：一个系统内部混乱程度越高，系统的熵值也就越高。后来，美国著名数学家香农（Shannon）将熵的概念引入信息论（Information Theory）中，提出信息熵（Information Entropy），信息论中的熵直接类似于统计热力学中的熵，用于描述事件的信息量或不确定度。对于随机变量![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image216.gif)，信息熵被定义为：

![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image218.gif)

其中，![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image220.gif)为![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image216.gif)的概率密度函数，![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image222.gif)为期望函数。

  本项目将教师的五类教学行为特征视为五个独立的事件。在明确特征属性之后，使用极差标准化方法对数据进行处理。具体而言，对于每种分类结果，根据教育学的先验知识，为每类特征与该类别之间的相关性进行指定。正相关特征进行正向影响特征的标准化处理，负相关特征则进行负向影响特征的标准化处理。令![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image224.gif)表示样本数，![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image226.gif)表示原始数据矩阵，其尺寸为![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image228.gif)，对于第![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image230.gif)个特征正向标准化处理：

![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image232.gif)

负向标准化处理：

![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image234.gif)

得到标准化数据矩阵![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image236.gif)。本项目用事件数值比重表征其概率。对于第![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image230.gif)个特征，数值比重计算公式为：

![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image239.gif)

计算第![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image240.gif)个特征的熵值：

![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image242.gif)

确定第![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image240.gif)个特征的熵权：

![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image244.gif)

  本项目设计了“互动型”和“灌输型”、“激昂型”和“庄严型”两组分类，各个分类与五类教学行为的相关性如下表所示。

表 各个分类与五类教学行为的相关性

|        | 举手示意 | 走动   | 指示引导 | 使用课本 | 书写板书 |
| ------ | -------- | ------ | -------- | -------- | -------- |
| 互动型 | 正相关   | 正相关 | 正相关   | 负相关   | 负相关   |
| 灌输型 | 负相关   | 负相关 | 负相关   | 正相关   | 正相关   |
| 激昂型 | 正相关   | 正相关 | 负相关   | 负相关   | 负相关   |
| 庄严型 | 负相关   | 负相关 | 正相关   | 正相关   | 正相关   |

每一个分类可以得出一组熵权向量![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image246.gif)，构成一个尺寸为![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image248.gif)的权重矩阵![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image250.gif)，推理分类评分值的公式即可表达为![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image252.gif)，评分矩阵![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image254.gif)尺寸为![img](file:///C:/Users/m1856/AppData/Local/Temp/msohtmlclip1/01/clip_image256.gif)，其含义为全体样本在四个类别上的评分。因为本项目设计了两组相对的分类标签，所以可以粗略地认为：“互动型”评分高于“灌输型”时，教师在该教学片段内的教学风格整体偏向于互动型，反之则偏向于灌输型；“激昂型”评分高于“庄严型”时，教师在该教学片段内的教学风格整体偏向于激昂型，反之则偏向于庄严型。

**此部分测试与维护需知：**

- **测试**：对每个模块进行单元测试，对整个系统进行集成测试。
- **维护**：定期更新算法模型，优化系统性能，修复发现的问题。

##### UML图2--多模态课堂分析UML图（包含类图与框架图）

**类图：**

![Untitled diagram-2024-11-01-025123](C:/Users/m1856/Desktop/mywork/mywork/Untitled diagram-2024-11-01-025123.png)

**系统框架图：**

![Untitled diagram-2024-11-01-024815](C:\Users\m1856\Desktop\mywork\mywork\Untitled diagram-2024-11-01-024815.png)

##### （3）系统前端设计与实时评价反馈机制

##### 主要模块介绍

###### 1 前端设计

使用Vue组件的方式来设计前端

主要Vue组件
`Dashboard.vue`：系统的概览界面，展示教学质量的总体情况。
`RealTimeFeedback.vue`：用于实时显示课堂反馈数据，如情绪状态和注意力分布。
`ReportViewer.vue`：用于查看和下载历史报告。
`UserProfile.vue`：用户资料和偏好设置页面。
`Auth.vue`：处理用户登录和权限验证的组件。

###### `Dashboard.vue`

- 描述：展示教学质量的总体情况，包括关键统计数据的图表和摘要。

- 数据来源：通过API从后端获取关键数据。

- 功能：

  - `showSummary()`：展示概览信息。
  - `refreshDashboard()`：刷新数据，定期更新

###### `ReportDetails.vue`

功能：展示单堂课程的详细分析数据，用户可以选择某个课程查看其分析结果。
数据来源：通过API请求特定课程的详细分析数据。
功能点：
`fetchReportDetails(courseId)`：根据课程ID获取详细数据。
`renderReportCharts()`：根据详细数据生成相应的图表展示。

###### `ReportViewer.vue`

- 功能：展示历史报告的列表，支持用户下载查看。
- 数据来源：通过API获取所有历史报告信息。
- 功能点：
  -`fetchReportList()`：获取历史报告的列表。
  -`downloadReport(reportId)`：下载选定报告文件。

###### `UserProfile.vue`

- 功能：用户管理页面，供用户更新个人资料，查看权限。
- 数据来源：从API获取用户资料和权限信息。
- 功能点：
  `fetchUserProfile()`：从后端API获取用户资料。
  `updateProfile()`：保存更新后的用户资料。

###### 2.数据流概述

**数据采集与上传**

- **数据源**：每堂课的教学音视频数据由教室中的摄像头、麦克风等设备采集。
- **数据内容**：采集的原始数据包括音频和视频文件，代表课堂的实际情况。
- **上传流程**：
  - 每堂课结束后，数据采集模块将原始数据打包，并上传至对象存储服务器，便于后续分析。
  - 上传的数据会暂存于对象存储服务器中，以便分析服务器可以在预定时间批量处理。

**数据存储与管理**

- **存储位置**：对象存储服务器用于存放原始音视频数据和其他大文件。
- **数据管理**：每份上传的数据都会生成唯一的文件ID和元数据（如课程ID、教师ID、时间戳等），存储在数据库中，便于索引和检索。
- **管理接口**：数据管理模块提供数据的上传和检索接口，便于分析服务器读取原始数据。

###### 3. 分析流程

###### **方案一： 定时分析**

- **触发时间**：系统在每天（或每周）的固定时间点启动数据分析任务。
- **数据预处理**：分析服务器在读取原始数据后，首先对其进行预处理（如音频降噪、视频清洗等）。
- **分析过程**：
  - **情绪分析**：识别课堂上的情绪状态，生成情绪分布结果。
  - **注意力分析**：分析学生的注意力集中度和视线分布，评估课堂参与度。
- **结果存储**：分析完成后生成的情绪、注意力等分析结果会以结构化数据的形式存储到数据库中，供后续查询和展示。

###### 方案二：自动菲尼分析+任务队列模式

- 触发机制：每节课数据上传完成后，会自动触发数据分析，将任务加入分析队列。
- 队列管理：分析队列按先入先出（FIFO）顺序处理上传的课程数据，确保分析任务依次执行。
- 任务监控：系统会监控分析任务状态，如“等待分析”、“分析中”、“已完成”等，确保任务按顺序处理。

###### 方案三：按用户请求触发分析

- 触发机制：系统中所有的课程数据上传后仅存储不分析，用户（如管理员或教师）登录并请求查看课程分析结果时，系统实时生成该课程的分析报告。
- 实现方式：
  - 用户点击分析请求后，系统在后台调用分析模块对指定课程的数据进行快速分析。
  - 分析结果生成后存储于数据库中，用户可立即查看或下载。

###### 4. 报告生成

- **生成方式**：数据分析完成后，报告生成模块根据分析结果生成详细的教学质量报告，调用上一部分的接口完成。
- **报告内容**：报告包含课堂的关键指标（如注意力、情绪等）及图表（如饼图、折线图）。
- **存储与访问**：
  - 生成的报告以PDF或其他可视化格式存储在对象存储服务器中，同时在数据库中记录报告的索引和元数据。
  - 用户可以通过前端系统访问报告的索引，并选择特定报告下载查看。

###### 5. 数据展示与用户访问

- **展示方式**：前端系统为用户提供多个页面，包括报告总览、详细报告、历史报告等。
- **数据获取**：
  - 报告总览页面从数据库中获取各课程的关键统计数据，显示教学质量的整体情况。
  - 详细报告页面可以按需查询单堂课程的详细数据，生成对应的图表和信息展示。
  - 历史报告页面提供报告下载链接，用户可以按时间顺序或课程名称查找并下载特定报告。
- **用户权限**：每个用户在访问报告时都会进行权限验证，确保数据的安全性和私密性。

###### 数据流示意

课堂数据采集 -> 批量上传 -> 定时分析 -> 报告生成 -> 数据展示与下载

###### 6.模块交互和接口说明

1. **数据上传模块**：
   - 接口：`/upload`
   - 功能：将采集的数据文件上传到对象存储服务器。

2. **数据分析模块**：
   - 接口：`/analyze`
   - 功能：定时批量分析上传的数据，生成情绪、注意力等结果。

3. **报告生成模块**：
   - 接口：`/report/generate`
   - 功能：根据分析数据生成报告文件，并存储在对象存储服务器。

4. **数据展示接口**：
   - 接口：`/reports/summary`、`/reports/{courseId}`、`/reports/download/{reportId}`
   - 功能：分别提供总览数据、详细数据和报告下载。

###### 系统优势与改进方向

**优势**

- **简化设计**：通过批处理的方式，避免实时处理的复杂性，降低了系统的开发和运维难度。
- **资源优化**：定时分析减少了系统对计算资源的持续消耗。
- **可扩展性**：非实时设计更容易增加新的分析维度或功能模块。

**改进方向**

- **实时扩展**：可以在未来逐步增加实时反馈模块，实现课堂实时数据采集和分析展示。
- **接口优化**：支持分页或按需加载数据，以优化大规模数据的展示效率。

##### UML图3-- 系统前端设计与实时评价反馈机制（包含类图与框架图）

**类图：**

![image-20241103150103875](C:\Users\m1856\AppData\Roaming\Typora\typora-user-images\image-20241103150103875.png)

**框架图：**

![image-20241103150507931](C:\Users\m1856\AppData\Roaming\Typora\typora-user-images\image-20241103150507931.png)



##### （4）设计过程利用原则--solid原则及应用实例

​	1.**单一职责原则 (SRP)**在我们的系统中，每个模块或类应专注于一个特定的功能。如评价指标体	   系构建模块只负责定义和管理评价指标，而多模态数据分析模块专注于处理和分析课堂数据。这样	   可以确保每个模块的代码更易于理解和维护，任何更改只需在相关模块中进行，而不会影响其他模	   块。

2. **开闭原则 (OCP)**系统设计应允许在不修改现有代码的情况下添加新功能。比方说，评价指标可以通过实现新的接口或继承现有的抽象类来扩展，而不需要修改现有的评价逻辑。这种设计使得系统能够适应未来的需求变化，如引入新的评价标准或分析方法。
3. **里氏替换原则 (LSP)**在继承结构中，确保子类可以替代父类而不改变系统的行为。若有一个基类 `EvaluationMetric`，其子类如 `BehaviorMetric` 和 `ContentMetric` 应该能够在任何使用 `EvaluationMetric` 的地方无缝替换。这确保了系统的稳定性和一致性。
4. **迪米特法则 (LoD)**通过降低模块之间的耦合度，系统的灵活性和可维护性得以提高。前端展示模块不需要直接与数据分析模块交互，而是通过中间层或接口进行通信。这减少了模块之间的依赖，使得每个模块可以独立开发和测试。
5. **接口隔离原则 (ISP)**确保每个接口只包含客户端所需的方法。例如，教师评价接口和学生反馈接口应分别定义，以避免不必要的方法实现。这种设计提高了代码的可读性和可理解性，使得每个接口更易于使用和实现。
6. **依赖倒置原则 (DIP)**高层模块不应依赖于低层模块，而是共同依赖于抽象。例数据分析模块和前端展示模块都应依赖于抽象的接口或服务层，而不是直接依赖于具体的实现。这种设计降低了模块之间的紧密耦合，使得系统更易于扩展和维护。通过结合这些原则，我们的高校课堂教学评价系统能够在复杂的功能需求下保持良好的结构和设计，确保系统的长期可持续发展。

##### （5）设计过程利用模型--迭代增量模型

###### **【1】模型概述：**

迭代增量模型结合了瀑布模型的结构化方法和敏捷开发的灵活性。它将项目分解为多个增量，每个增量都是一个可交付的产品版本。每个增量在开发过程中都会经历需求分析、设计、实现和测试等阶段。通过不断的迭代和增量交付，项目可以逐步完善和扩展。

###### **【2】适用性分析**

1. **灵活应对需求变化：**在高校课堂教学评价系统中，用户需求可能会随着教育政策、技术进步和用户反馈而变化。迭代增量模型允许在每个迭代中重新评估和调整需求，确保系统始终符合用户的最新需求。
2. **持续交付和反馈：**通过每个增量的交付，用户可以在早期阶段就使用系统的部分功能，并提供反馈。这种持续的反馈机制有助于及时发现问题并进行调整，提高系统的用户满意度和实用性。
3. **风险管理：**由于项目的复杂性和技术挑战（如多模态数据分析、实时反馈机制等），迭代增量模型可以通过早期交付和测试来识别和缓解风险。每个增量的成功交付都能降低项目整体的风险。
4. **提高生产效率：**通过分阶段交付，开发团队可以更好地管理资源和时间，专注于当前迭代的目标。这种方法有助于提高开发效率和产品质量。在项目中的应用初始迭代：专注于核心功能的开发，如评价指标体系的构建和基本的多模态数据分析功能。确保系统的基本框架和关键功能能够正常运行。
5. **后续迭代：**逐步引入高级功能，如复杂的跨模态数据分析、实时反馈机制和可视化展示平台。根据用户反馈和需求变化，调整和优化系统功能。
6. **持续改进：**在每个迭代结束后，进行回顾和评估，识别改进点并计划下一次迭代的目标。通过这种方式，系统能够不断演进和优化。结论迭代增量模型为高校课堂教学评价系统的开发提供了灵活性和适应性，能够有效应对项目中的不确定性和变化需求。通过持续的交付和反馈，确保系统的高质量和用户满意度。

#### 三、重构、复⽤的思考及最终⽅案  

##### thinking

软甲总是由简单软件向复杂软件转变，当软件开始由简单软件转变为复杂软件时我们就需要复用、重构，复用、重构是软件发展的必然。在开发高校课堂教学评价系统的过程中，重构和代码复用是确保系统长期可维护性和扩展性的关键策略。**重构的好处有很多，比如：提高代码质量**：随着项目的演进，代码可能变得复杂和难以理解。通过重构提高代码的清晰度和简洁性，使其更易于维护和扩展。**减少重复代码：**在多模态数据分析和评价指标体系中，可能存在重复的逻辑。重构可以帮助识别和消除这些重复代码，提高代码的可维护性。**遵循最佳实践：**通过重构，我们可以调整代码以符合SOLID原则等最佳实践，确保系统的设计更为健壮。**增加扩展性：**重构使代码更易于扩展，便于在未来添加新功能，如引入新的数据分析算法或评价指标。**提高可读性：**清晰和整洁的代码更容易阅读和理解，尤其在团队合作和知识共享中至关重要。**修复bug：**在重构过程中，深入理解代码逻辑，常常能发现隐藏的bug并进行修复。降低维护成本：通过提高代码质量和可读性，重构可以显著降低长期的维护成本。

##### methods

1. ###### 运用“抽取方法”解决大函数问题

   在多模态数据分析模块中，会出现处理复杂数据的超级大函数。需要：

   **分析函数逻辑：**在处理视频、音频和文本数据时，识别出功能相对独立的代码段。视频处理中的人脸检测、视线检测和表情识别分别抽取为独立的方法。

   **抽取独立方法：**将这些代码段抽取为独立的方法，确保每个方法只负责一个特定任务。这不仅提高了代码的可读性，还便于单独测试和维护。

   **参数封装：**如果方法需要多个参数，考虑将参数封装为对象，以减少方法签名的复杂性。如将视频帧、音频片段和文本段落封装为数据对象，传递给相应的处理方法。

2. ###### 运用“抽取类”解决大对象问题

   在系统中，某些类可能会承担过多的职责，例如同时处理数据分析和结果展示:

   **识别职责：**明确每个类的核心职责，避免职责过于分散。将数据采集、数据处理和结果展示分离为不同的类。

   **抽取新类：**将不同职责的代码抽取到新的类中,创建独立的DataCollector、DataAnalyzer和ResultPresenter类。

   **模块化设计：**为前端开发创建独立的组件库，以便于复用和维护,创建可复用的UI组件库来展示分析结果。

3. ###### 运用“抽取父类”提高代码复用

   在评价指标体系中，会有多个指标共享相似的逻辑：

   **识别重复代码：**找出不同指标中重复的逻辑，最常见的有计算平均分、标准差等统计方法。

   **抽取父类：**将这些重复逻辑抽取到一个父类中，子类通过继承来复用这些逻辑,创建一个BaseMetric类，提供通用的计算方法。

   **使用抽象类或接口：**定义通用的接口或抽象类，以便于不同指标的实现。思考如定义IMetric接口，确保所有指标类实现必要的方法。

4. ###### 运用“两顶帽子”解决新功能的扩展

   在系统需要引入新功能时：

   **重构现有代码：**在不添加新功能的前提下，重构代码以适应新功能的扩展。例重构数据分析模块以支持插件式算法扩展。

   **实现新功能：**在重构完成后，逐步实现新功能，确保系统的稳定性。比如添加新的情感分析算法以增强课堂情绪检测。

5. ###### 运用设计模式降低代码耦合

   在系统设计中，模块之间不应有不必要的直接依赖。为了解决这一问题：

   **使用设计模式：**观察者模式用于实时反馈机制，策略模式用于选择不同的分析算法，降低模块之间的耦合。

   **模块化设计：**确保每个模块只通过接口与其他模块交互，避免直接依赖，使用接口定义数据分析模块与前端展示模块的交互。

6. ###### **运用“领域驱动设计”拥抱变化**

   **分离领域层：**将业务逻辑与技术实现分离，确保领域层的独立性。领域层应专注于教学评价的核心逻辑，而不依赖于具体的技术实现。

   **解耦技术依赖：**领域层不应直接依赖于具体的技术实现，如数据库或前端框架。通过使用服务接口和依赖注入，确保领域层的灵活性。

7. ###### **使用小步快跑的开发模式**

   **快速迭代：**每次迭代只引入一个小的功能改进，确保系统的稳定性。比方先实现基本的评价指标计算，再逐步引入高级分析功能。

   **持续验证：**在每个迭代中进行功能验证，确保新功能的正确性。通过自动化测试和用户反馈，及时调整和优化系统。

#### 四、UML图重现

###### 多模态课堂分析uml

![Untitled diagram-2024-11-01-025123](C:/Users/m1856/Desktop/mywork/mywork/Untitled diagram-2024-11-01-025123.png)

![Untitled diagram-2024-11-01-024815](C:\Users\m1856\Desktop\mywork\mywork\Untitled diagram-2024-11-01-024815.png)

###### 系统前端设计与实时评价反馈机制uml

<img src="C:\Users\m1856\AppData\Roaming\Typora\typora-user-images\image-20241103150103875.png" alt="image-20241103150103875" style="zoom:67%;" />

![image-20241103150507931](C:\Users\m1856\AppData\Roaming\Typora\typora-user-images\image-20241103150507931.png)

#### 五、可能出现的代码质量问题及相关解决⽅案  

1. #### 代码质量问题

   1.1 **缺乏严格的编码规范和标准问题**：团队成员可能会使用不同的编码风格，导致代码不一致，难以阅读和维护。

   **解决方案：**制定并遵循样式指南：采用行业标准的样式指南，如`Airbnb`的JavaScript风格指南，确保代码风格一致。使用`Linters`：配置`ESLint`、`TSlint`等工具自动检查代码风格，确保代码符合预定义的规范。

   **1.2 不合理的算法设计问题：**算法设计不合理可能导致性能问题和资源浪费。

   **解决方案：**代码审查：定期进行代码审查，识别并优化低效的算法。性能测试：使用性能测试工具识别瓶颈，优化关键路径的算法。

   **1.3 潜在的漏洞和错误难以发现和修复问题：**代码中可能存在未被发现的漏洞和错误，影响系统的稳定性和安全性。**解决方案：**静态代码分析：使用`SonarQube`等工具进行静态代码分析，识别潜在的漏洞和错误。持续集成：在`CI/CD`管道中集成自动化测试，确保每次代码变更都经过严格的测试。

2. #### 需求管理问题

   **2.1 不清晰、不完整或不准确的需求定义问题：**需求不明确可能导致开发偏离目标，增加返工成本。

   **解决方案：**需求文档：详细记录需求文档，确保所有团队成员对需求有一致的理解。需求评审：在开发前进行需求评审，确保需求的清晰性和完整性。

   **2.2 需求变更导致开发延迟和重复劳动问题：**频繁的需求变更可能导致开发计划被打乱，增加开发成本。

   **解决方案：**敏捷开发：采用敏捷开发方法，灵活应对需求变更。迭代计划：在每个迭代开始前锁定需求，减少中途变更。

3. #### 测试困境

   **3.1 手动测试工作量大，周期长，容易出错问题：**手动测试耗时且容易遗漏问题，影响发布周期。

   **解决方案：**自动化测试：使用`Selenium`、`JUnit`等工具进行自动化测试，减少手动测试工作量。测试覆盖率：确保自动化测试覆盖率达到80%以上，涵盖关键功能和边界情况。

   **3.2 自动化测试覆盖率不足，无法全面检测软件功能和性能问题：**自动化测试覆盖率低可能导致关键问题未被发现。

   **解决方案：**测试驱动开发（`TDD`）：在开发过程中编写测试用例，确保新功能的测试覆盖。持续测试：在`CI/CD`管道中集成自动化测试，确保每次代码变更都经过严格的测试。通过识别和解决这些代码质量问题，我们可以确保高校课堂教学评价系统的高质量和稳定性，支持系统的长期可持续发展。
